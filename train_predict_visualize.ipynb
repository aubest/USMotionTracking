{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUST Motion Tracking Project\n",
    "MÃ©lanie Bernhardt - ETH Zurich - Data Science MSc\n",
    "\n",
    "This notebook provides a simple way to train the model, to predict the location of features from a saved model and to visualize the predictions. \n",
    "\n",
    "### First set up the environment\n",
    "WARNING: in order to be able to run this notebook the `DATA_PATH`, `EXP_PATH`and `TEST_PATH` have to be properly set prior to starting the jupyter server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataLoader import DataLoader\n",
    "from network import create_model\n",
    "from custom_KFold import MyKFold\n",
    "from utils import get_logger, get_default_params, plot_img_template\n",
    "from global_tracking import train, predict, run_global_cv\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ DATA AND SAVING DIRS SETUP ========== #\n",
    "data_dir = os.getenv('DATA_PATH')\n",
    "test_dir = os.getenv('TEST_PATH')\n",
    "exp_dir = os.getenv('EXP_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = '2layers_new'\n",
    "params_dict = {'dropout_rate': 0.5, 'n_epochs': 100,\n",
    "               'h3': 0, 'embed_size': 128, 'width': 60}\n",
    "\n",
    "checkpoint_dir = os.path.join(exp_dir, exp_name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "params_dict = get_default_params(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: train the model from scratch\n",
    "If a validation generator is provided then it uses early stopping else not. `train` automatically saves the model weigths and the temporal estimators to the checkpoint dir (necessary for `predict` to work properly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindirs = np.asarray([dI for dI in os.listdir(data_dir) if (\n",
    "                        os.path.isdir(os.path.join(data_dir, dI))\n",
    "                        and not dI == 'feats_matrices')])\n",
    "model, est_c1, est_c2 = train(traindirs, data_dir,\n",
    "                              upsample=False, \n",
    "                              params_dict=params_dict,\n",
    "                              checkpointdir=checkpoint_dir,\n",
    "                              logger=None,\n",
    "                              validation_gen=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Predict from a saved model\n",
    "The `predict` function restores the models saved in the `checkpoint_dir`. It runs computes the feature location for every frame of every sequences in the test directories. For each test sequence, the results are saved in a tab separated file named `SequenceName_PointNumber.txt` (as required by the submission format of the CLUST Challenge). The files are also stored in the `checkpoint_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdirs = np.asarray([dI for dI in os.listdir(test_dir) if (\n",
    "                        os.path.isdir(os.path.join(test_dir, dI))\n",
    "                        and not dI == 'feats_matrices')])\n",
    "predict(testdirs, checkpoint_dir, data_dir, params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Run the cross-validation on the whole procedure\n",
    "Runs the across-sequence cross-validation. Each neural model + temporal models are trained on 20 sequences and then predictions are computed for the remaining 4 sequences (5-folds). The results are recorded in a `logfile.log` in the checkpoint directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOGGER SETUP ======== #\n",
    "logger = get_logger(checkpoint_dir)\n",
    "\n",
    "# ========= PRINT CONFIG TO LOG ======== #\n",
    "logger.info('Running %s experiment ...' % exp_name)\n",
    "logger.info('\\n Settings for this expriment are: \\n')\n",
    "for key in params_dict.keys():\n",
    "    logger.info('  {}: {}'.format(key.upper(), params_dict[key]))\n",
    "logger.info('Saving checkpoint to {}'.format(checkpoint_dir))\n",
    "\n",
    "# ======== KFold iterator ========= #\n",
    "np.random.seed(seed=42)\n",
    "kf = MyKFold(data_dir, n_splits=5)\n",
    "fold_iterator = kf.getFolderIterator()\n",
    "\n",
    "# ======== Run global CV ======= #\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.666)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "tf.keras.backend.set_session(sess)\n",
    "run_global_cv(fold_iterator, data_dir, checkpoint_dir, logger, params_dict, upsample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your predictions\n",
    "\n",
    "### Get the prediction and the ground truth if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_to_visualize = ''\n",
    "type_data = 'training'\n",
    "checkpoint_dir = os.path.join(exp_dir, exp_to_visualize)\n",
    "sequence_to_visualize = 'MED-02-3' # data folder to get the images from\n",
    "feature_to_visualize = 'MED-02-3_4.txt'# name of the .txt file\n",
    "if type_data=='training':\n",
    "    img_dir = os.path.join(data_dir, sequence_to_visualize, 'Data')\n",
    "else:\n",
    "    img_dir = os.path.join(test_dir, sequence_to_visualize, 'Data')\n",
    "pred_feat1 = pd.read_csv(os.path.join('/Users/melaniebernhardt/Downloads', # exp_to_visualize \n",
    "                                      feature_to_visualize),\n",
    "                                     sep=',', #'\\s+\n",
    "                                     decimal='.', header=None, names = ['id', 'c1','c2'])\n",
    "if type_data=='training':\n",
    "    annotation_dir = os.path.join(data_dir, sequence_to_visualize, 'Annotation')\n",
    "    true_feat1 = pd.read_csv(os.path.join(annotation_dir, feature_to_visualize),\n",
    "                                         sep='\\s+',\n",
    "                                         decimal='.', header=None, names = ['id', 'c1','c2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the initial point with the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "c1, c2 = pred_feat1.loc[pred_feat1['id']==i, ['c1', 'c2']].values[0]\n",
    "try:\n",
    "    img = np.asarray(Image.open(os.path.join(img_dir, '{:04d}.png'.format(int(i)))))\n",
    "except FileNotFoundError:\n",
    "    img = np.asarray(Image.open(os.path.join(img_dir, '{:05d}.png'.format(int(i)))))\n",
    "plot_img_template(c1, c2, img, width=60, height=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the temporal evolution of feature location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred_feat1.id, pred_feat1.c1, 'b')\n",
    "plt.plot(true_feat1.id, true_feat1.c1, 'r*')\n",
    "plt.show()\n",
    "plt.plot(pred_feat1.id, pred_feat1.c2, 'b')\n",
    "plt.plot(true_feat1.id, true_feat1.c2, 'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the tracking as a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_list = pred_feat1.loc[:, 'c1'].values\n",
    "c2_list = pred_feat1.loc[:,'c2'].values\n",
    "for i in range(1,2000,50):\n",
    "    try:\n",
    "        img = np.asarray(Image.open(os.path.join(img_dir, '{:05d}.png'.format(i))))\n",
    "    except FileNotFoundError:\n",
    "        img = np.asarray(Image.open(os.path.join(img_dir, '{:04d}.png'.format(i))))\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(c1_list[i-1], c2_list[i-1], 3, 'r')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.show())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
